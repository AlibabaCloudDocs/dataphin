# 用户必读 {#concept_av1_vrt_zgb .concept}

本文为您介绍Dataphin的使用须知。

## 使用须知 {#section_h5d_pst_zgb .section}

为保障软件系统稳定，Dataphin有部分使用上的约束或建议，详情如下。

|操作|Dataphin使用约束|
|--|------------|
|管理中心-成员管理| -   超级管理员（即超管）是用户下单购买Dataphin后，系统自动初始化生成，RAM主账号即为超级管理员，一个Dataphin系统仅一个该角色用户，拥有系统内所有权限。
-   阿里云RAM账号体系下，如需更新用户列表、用户信息，需要超级管理员用户登录[管理控制台](../../../../cn.zh-CN/用户指南/界面引导/管理控制台.md#)，配置AccessKey做授权，然后超级管理账号进行账号系统同步后，即可获取RAM主账号下的子账号，并添加为Dataphin的成员。

 |
|管理中心-计算引擎配置| -   全局配置，只有系统内计算引擎源为空的情况下，才能由超管更新。
-   MaxCompute计算类型下，推荐配置Endpoint为http://service.cn.maxcompute.aliyun-inc.com/api，如您需要使用数据萃取功能（公测期间，数据萃取功能暂未上线），建议咨询MaxCompute产品售后，确认您数据中心所在Region支持Spark的Endpoint地址。

 |
|计算引擎类型-选择设置|计算引擎设置，需要提前采购计算引擎Maxcompute资源，系统以此来支持相关数据的建设工作。 -   需要选择计算引擎类型（目前开放MaxCompute），配置计算引擎所在的集群，如Endpoint等信息。系统以此来支持该计算引擎类型下、该集群上，相关数据的建设工作，请根据您的计算引擎的集群情况选择设置。
-   如果您需要用到Spark on MaxCompute做计算，请注意咨询MaxCompute产品团队，确认您的MaxCompute计算引擎所在的Region是否开通Spark服务，如未开通，您的Spark任务执行会不成功。
-   请您以Dataphin为唯一入口进行数据构建与管理，以免出现元数据错误、权限异常等问题。

 |
|数据源管理-新增| -   建议配置的数据源AccessKey为管理级权限，可以通过配置主账号AccessKey，或者给子账号AccessKey授予MaxCompute所有权限来实现。
-   不建议将同一个物理数据库（配置完全相同）配为两个数据源。

 |
|项目管理-项目名| -   建议当配置数据源为Maxcompute类型时，项目英文名必须与Maxcompute的Project英文名一致。
-   项目名不可以`LD_`/`ld_`开始，以免与业务板块名冲突，导致查询功能不可用。

 |
|项目管理-计算引擎源配置| -   对于已配置为项目数据源的物理数据库，不建议再从其他非Dataphin控制台进行数据的增、删、改操作。
-   不建议项目配置的引擎源跨集群。

 |
|研发工作台-数据处理| -   不支持项目所属的计算引擎源在跨集群的情况下读取数据。
-   非Dataphin创建的表，Dataphin中元数据可能无法获取或者更新相关信息。

 |
|研发工作台-规范建模|建议谨慎命名规范定义及逻辑表对象英文名，并且推荐使用英文小写，以免因下游依赖约束导致英文名不可改且不易读。尽可能使用英文缩写，以免字段名称超出数据库限制，导致数据生产出错。|
|研发工作台-即席查询|逻辑表查询时必须带业务板块英文名为前缀，跨项目物理表使用需要带项目英文名为前缀。 如果您需要查询开发环境数据，请在生产名称后加上**\_dev**，系统会自动将生产业务板块、生产项目生成对应的变量。例如，您拥有业务板块LD\_Trade，则系统自动生成业务板块变量$\{LD\_Trade\}。该变量在开发环境执行时默认被替换为LD\_Trade\_dev，在生产环境执行时默认被替换为LD\_Trade。您也可以在执行时设置固定的值，提高代码在不同环境执行时的灵活性。

 |

